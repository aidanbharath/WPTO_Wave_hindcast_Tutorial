{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DOE WPTO Wave Hindcast Data Access Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Table of Contents\n",
    "\n",
    "- **Section 1**: Dataset Description\n",
    "- **Section 2**: Installation and Setup of the REsource eXtraction Toolkit (rex)\n",
    "- **Section 3**: Working with the rex CLI to access the Datasets\n",
    "- **Section 4**: Working with rex and Python to access the Datasets\n",
    "- **Section 5**: Data Processing and Plotting examples with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Section 1: Dataset Description\n",
    "\n",
    "**There are two major sub-datasets within the overarching dataset:** \n",
    "\n",
    "\n",
    "**1.** The high-spatial-resolution dataset (hereafter the *'spatial dataset'*) spans the U.S. Exclusive Economic Zone (EEZ) with an unstructured grid that has ~200 m resolution in shallow water. The time step resolution for this spatial data is 3-hours and spans 32 years, 01/01/1979  - 12/31/2010.\n",
    " \n",
    "\n",
    "**2.** The *'virtual buoy dataset'* is also available at specific locations within the large spatial domain. These virtual buoys span the same 32-years of the spatial dataset however the time resolution is 1-hour, and these data also include the wave directional spectrum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Spatial Dataset:\n",
    "\n",
    "- The spatial dataset is organized into yearly files (each file contains all variables and locations in that year) and they are located on AWS at: \n",
    "\n",
    "    **`/nrel/US_wave/US_wave_{year}.h5`**\n",
    "\n",
    "\n",
    "- Dataset variables included are indexed by **'coordinates'** (latitude and longitude), and a **'time_index'**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Included Spatial Variables: \n",
    "\n",
    "| Variable Name | Units |\n",
    "| :------------ | :---: |\n",
    "| energy_period | seconds |\n",
    "| maximum_energy_period | degrees_true |\n",
    "| mean_absolute_period | seconds |\n",
    "| mean_zero-crossing_period | seconds |\n",
    "| omni-directional_wave_power | Watts |\n",
    "| peak_period | seconds |\n",
    "| significant_wave_height | meters |\n",
    "| water_depth | meters |\n",
    "| spectral_width | none |\n",
    "| directionality_coefficient | none |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Virtual Buoy Dataset:\n",
    "\n",
    "- The virtual buoy dataset is located on AWS at: \n",
    "\n",
    "    **`/nrel/US_wave/virtual_buoy/US_virtual_buoy_{year}.h5`**\n",
    "    \n",
    "\n",
    "- This dataset includes **all variables** in the spatial dataset, and also includes the directional wave spectrum (indexed by 'time_index','frequency', 'direction', and 'coordinates'):\n",
    "  \n",
    "| Variable Name | Units |\n",
    "| :------------ | :---: |\n",
    "| direction_wave_spectrum | meters<sup>2</sup>degree<sup>-1</sup>Hz<sup>-1</sup> |\n",
    "| maximum_energy_direction | degrees_true |\n",
    "| mean_wave_direction | degrees_true |\n",
    "| frequency_bin_edges | Hz |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Section 2: Installation and Setup or the REsource eXtraction Toolkit (rex)\n",
    "\n",
    "In this section we will cover the process for install the rex package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Section 3: Working with the rex CLI to Access the Datasets\n",
    "\n",
    "The rex CLI offers simple and covenient commands to access and download variable data from the WPTO Wave Hiindcast Dataset.\n",
    "\n",
    "The following section of this tutorial will provide examples of how to work with the rex CLI:\n",
    " - **Example 3.1**: The WaveX Command\n",
    " - **Example 3.2**: Accessing a Single Site\n",
    " - **Example 3.3**: Accessing multiple locations\n",
    " - **Example 3.4**: Accessing data over multiple years\n",
    " - **Example 3.5**: Accessing the Directional Wave Spectrum Data from the Virtual Buoys\n",
    "\n",
    "The goal is to provide a means of accessing data that can then be process by any other means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 3.1: The WaveX Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "WaveX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 3.2: Accessing a Single Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "WaveX -h5 '/nrel/US_wave/US_wave_1990.h5' -o './' site -d 'significant_wave_height' -ll '44.624076' '-124.280097'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls significant_wave_height-413889.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from pandas import DataFrame\n",
    "a = DataFrame(array([(44.624076,-124.280097),(45.624076,-125.280097)]),columns=['latitude','longitude'])\n",
    "\n",
    "a.to_csv('./sites.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 3.3: Accessing Multiple Locations\n",
    "\n",
    "Calling multiple locations will have the data compiled into a single file.\n",
    "\n",
    "This CLI command works from a '.csv' or 'gid' with latitude, longitude pairs to pull data from AWS and and file name needs to be passed as an option to 'multi-site'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "WaveX -h5 '/nrel/US_wave/US_wave_1990.h5' -o './'  multi-site -s './sites.csv' dataset -d 'significant_wave_height' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 3.4: Accessing Data over Multiple Years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 3.5: Accessing the Directional Wave Spectrum Data from the Virtual Buoys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Section 4: Working with rex and Python to access the Datasets\n",
    "\n",
    "In the following section we provide examples to access WPTO Wave Hindcast Dataset using the rex toolkit within a python environment.\n",
    "\n",
    "Examples provided include:\n",
    "- **Example 4.1**: Accessing dataset metadata parameters:\n",
    "    - *meta-data*\n",
    "    - *time_index*\n",
    "    - *coordinates* (latitude/longitude pairs)\n",
    "- **Example 4.2**: Extracting Data from a single site\n",
    "- **Example 4.3**: Extracting Data from multiple sites\n",
    "- **Example 4.4**: Extracting Data over multiple years\n",
    "    - Using Filename Wildcards\n",
    "    - Specifying Years\n",
    "- **Example 4.5**: Working with the Virtual Buoy Dataset\n",
    "    - Accessing *meta-data* parameters\n",
    "    - Accessing Bulk Parameters over Multiple Years\n",
    "- **Example 4.6**: Viewing the Directional Wave Spectrum data\n",
    "- **Example 4.7**: Exporting Python Datasets to various other types\n",
    "\n",
    "The goal is to provide an overview of how python can be used to interact with the available datasets. Each individual example below is self contained and can be copied to another script if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 4.1: Accessing Dataset metadata Parameters\n",
    "\n",
    "The following examples illustrate basic examples using NREL-rex to access and download parts of the WPTO Wave Hindcast dataset.\n",
    "\n",
    "Datasets are returned as Pandas DataFrame objects. See the Pandas [documentation](https://pandas.pydata.org/pandas-docs/stable/) \n",
    "for more information about working with Pandas objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### \"*meta-data*\" Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from rex import WaveX\n",
    "waveFile = f'/nrel/US_wave/US_wave_1990.h5'\n",
    "\n",
    "with WaveX(waveFile, hsds=True) as waves:\n",
    "    # meta is an object that contains location information for each data point\n",
    "    meta = waves.meta \n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### \"*time_index*\" Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rex import WaveX\n",
    "waveFile = f'/nrel/US_wave/US_wave_1990.h5'\n",
    "\n",
    "with WaveX(waveFile, hsds=True) as waves:\n",
    "    # time_index contains all of the years within the file\n",
    "    time_index = waves.time_index \n",
    "time_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### \"*coordinates*\" (latitude/longitude pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rex import WaveX\n",
    "waveFile = f'/nrel/US_wave/US_wave_1990.h5'\n",
    "\n",
    "with WaveX(waveFile, hsds=True) as waves:\n",
    "    # coordinates contains all the lat/lon pars within the dataset\n",
    "    coordinates = waves.coordinates \n",
    "coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 4.2: Extracting data from a Single Site\n",
    "A single latitude/longitude pair can be given to extract data nearest to that location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the timeseries of significant_wave_height closest to a coordinate pair\n",
    "from rex import WaveX\n",
    "waveFile = f'/nrel/US_wave/US_wave_1990.h5'\n",
    "lat_lon = (44.624076,-124.280097)\n",
    "parameters = 'significant_wave_height'\n",
    "    \n",
    "with WaveX(waveFile, hsds=True) as waves:\n",
    "    swh_single = waves.get_lat_lon_df(parameters, lat_lon)\n",
    "swh_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 4.3: Extracting data from Multiple Sites\n",
    "A list of latitude/longitude pairs can be passed to extract data from multiple sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the timeseries of significant_wave_height closest to multiple coordinate pairs\n",
    "from rex import WaveX\n",
    "waveFile = f'/nrel/US_wave/US_wave_1990.h5'\n",
    "lat_lon = [(44.624076,-124.280097),(43.489171,-125.152137)] # set lat_lon to a list of lat/lon pairs\n",
    "parameters = 'significant_wave_height'\n",
    "    \n",
    "with WaveX(waveFile, hsds=True) as waves:\n",
    "    swh_multi = waves.get_lat_lon_df(parameters, lat_lon)\n",
    "swh_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 4.4: Extracting Data over Multiple Years\n",
    "The previous examples return data for a single year only. To extract data over a number of years, use the `MultiYearWaveX` class which can accept wildcards witihin the filename:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using filename Wildcards:\n",
    "\n",
    "Using a wildcard in the dataset filename will tell `'MultiYearWaveX'` to access all datasets matching the written specified filename. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveFile_wildcard = f'/nrel/US_wave/US_wave_199*.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from rex import MultiYearWaveX # Yearly concatonation requires the MultiYearResource function\n",
    "lat_lon = (44.624076,-124.280097)\n",
    "parameters = 'significant_wave_height'\n",
    "    \n",
    "with MultiYearWaveX(waveFile_wildcard,hsds=True) as mYears:\n",
    "    swh_multi_year = mYears.get_lat_lon_df(parameters, lat_lon)\n",
    "swh_multi_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Specifying Years to Access:\n",
    "\n",
    "We can pass a list of specific years to `MultiYearWaveX` to access. \n",
    "\n",
    "Note in this case we still need to specify the dataset's file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveFiles = f'/nrel/US_wave/US_wave_*.h5'\n",
    "years = [1989,1990,1991,1992,1993,2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from rex import MultiYearWaveX # Yearly concatonation requires the MultiYearResource function\n",
    "lat_lon = (44.624076,-124.280097)\n",
    "parameters = 'significant_wave_height'\n",
    "    \n",
    "with MultiYearWaveX(waveFiles,years=years,hsds=True) as mYears:\n",
    "    swh_multi_year = mYears.get_lat_lon_df(parameters, lat_lon)\n",
    "swh_multi_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 4.5: Working with the Virtual Buoy Datasets\n",
    "\n",
    "Virtual buoys were created during the larger UnSWAN model runs and contain 1-hour timestep data with directional spectrum data\n",
    "\n",
    "These data can be accessed using the same basic approaches described above, but using a different path that points to these data: `/nrel/US_wave/virtual_buoy/US_virtual_buoy_{year}.h5`\n",
    "\n",
    "The Virtual Buoy data is structured in the same way as the Spatial Dataset. Accessing the data is accomplished in the same way, and differs only in the dataset's directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Virtual Buoy \"*time_index*\" Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rex import WaveX\n",
    "vBuoy = f'/nrel/US_wave/virtual_buoy/US_virtual_buoy_1995.h5'\n",
    "\n",
    "with WaveX(vBuoy, hsds=True) as waves:\n",
    "    time_index = waves.time_index \n",
    "time_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Virtual Buoy Bulk Parameter Access over Multiple Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rex import MultiYearWaveX\n",
    "multi_year_vBuoy = f'/nrel/US_wave/virtual_buoy/*.h5'\n",
    "years = [1979,1987,1999,2008]\n",
    "lat_lon = (44.624076,-124.280097)\n",
    "parameters = 'significant_wave_height'\n",
    "    \n",
    "with MultiYearWaveX(multi_year_vBuoy,years=years,hsds=True) as mYears:\n",
    "    swh_buoy = mYears.get_lat_lon_df(parameters, lat_lon)\n",
    "swh_buoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 4.6: Accessing and Viewing with the Virtual Buoy Directional Wave Spectum\n",
    "\n",
    "Directional wave spectrum data is more complicated to work with in that we have the extra dimentions of frequency and direction within the dataset. These dataset are returned from HSDS as [Pandas Multi-index Dataframes](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html).\n",
    "\n",
    "This format flattens the 3-dimensional array along a single axis so the data itself can still be easily displayed and interpreted.\n",
    "\n",
    "This examples shows the form of the `'directional_wave_spectrum'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rex import WaveX\n",
    "vBuoy = f'/nrel/US_wave/virtual_buoy/US_virtual_buoy_1995.h5'\n",
    "lat_lon = (44.624076,-124.280097)\n",
    "spc_name = 'directional_wave_spectrum'\n",
    "\n",
    "with WaveX(vBuoy, hsds=True) as waves:\n",
    "    spc_buoy = waves.get_lat_lon_df(spc_name, lat_lon)\n",
    "spc_buoy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 4.7: Exporting the Datasets from Python to Various other Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Section 5: Data-Processing and Plotting Examples with Python\n",
    "\n",
    "This section of the tutorial offers basic introductions to working with the data within python. \n",
    "\n",
    "Examples include:\n",
    "\n",
    "- **Example 5.1**: Plotting a Year of Data from the Spatial Dataset\n",
    "- **Example 5.2**: Creating a *Typical* year Dataset\n",
    "- **Example 5.3**: Working with the Directional Wave Spectrum and Polar Plots \n",
    "- **Example 5.4**: Creating and Plotting a Joint Probability Distribution\n",
    "- **Example 5.5**: Creating and Plotting a Directionaly Dependent JPD\n",
    "\n",
    "The goal of these examples are to offer a starting point for more elaborate and extensive use of the datasets in further studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 5.1: Plotting a Year of Data from the Spatial Dataset\n",
    "\n",
    "Extracting a year of data now should be quick and easy matter of using **rex** to gather, download and organise the data from AWS servers. \n",
    "\n",
    "What follows below is a *'TwinX'* plotting method to view a comparison between Significant Wave Height and Omni-Directional Wave Power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rex import WaveX\n",
    "waveFile = f'/nrel/US_wave/US_wave_1995.h5'\n",
    "lat_lon = (44.624076,-124.280097)\n",
    "swh_name, owp_name = 'significant_wave_height', 'omni-directional_wave_power'\n",
    "    \n",
    "with WaveX(waveFile, hsds=True) as waves:\n",
    "    swh = waves.get_lat_lon_df(swh_name, lat_lon)\n",
    "    owp = waves.get_lat_lon_df(owp_name, lat_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot makes use of python's **matplotlib** package to format and display the data just downloaded in the previous cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format ='retina' #notebook commands are not needed in separate scripts\n",
    "%matplotlib widget #notebook commands are not needed in separate scripts\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "font = {'family' : 'DejaVu',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 12}\n",
    "\n",
    "mpl.rc('font', **font)\n",
    "\n",
    "host = host_subplot(111)\n",
    "par = host.twinx()\n",
    "\n",
    "host.set_xlabel(\"Time\")\n",
    "host.set_ylabel('Significant Wave Height (m)')\n",
    "par.set_ylabel('Omni-Directional Wave Power (kW/m)')\n",
    "\n",
    "p1, = host.plot(swh.index, swh.values, label='Significant Wave Height')\n",
    "p2, = par.plot(owp.index, owp.values/1000, label='Omni-Directional Wave Power')\n",
    "\n",
    "leg = plt.legend()\n",
    "\n",
    "host.yaxis.get_label().set_color(p1.get_color())\n",
    "leg.texts[0].set_color(p1.get_color())\n",
    "\n",
    "par.yaxis.get_label().set_color(p2.get_color())\n",
    "leg.texts[1].set_color(p2.get_color())\n",
    "\n",
    "plt.title('WPTO Wave Hindacast Data for 1995')\n",
    "plt.grid(linestyle=':')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This plotting routine makes use of the data available within the Spatial dataset and so minimal changes are needed in order to plot different variable combinations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 5.2: Creating a *Typical* Year Dataset\n",
    "\n",
    "Defining the meaning of a *typical* year for bulk wave parameters is not necessarily straight foreward. In the example that follows we simple consider the mean value of each parameter across the years under consideration as the definition of the *typical* case. \n",
    "\n",
    "This example highlights some simple methods of comparing yearly data against a *typical* case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rex import MultiYearWaveX\n",
    "from numpy import arange\n",
    "\n",
    "waveFile = f'/nrel/US_wave/US_wave_19*.h5'\n",
    "years = arange(1995,2000,1)\n",
    "lat_lon = (44.624076,-124.280097)\n",
    "owp_name = 'omni-directional_wave_power'\n",
    "    \n",
    "with MultiYearWaveX(waveFile,years=years, hsds=True) as waves:\n",
    "    owp = waves.get_lat_lon_df(owp_name, lat_lon)\n",
    "owp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the [Pandas Group-by Functionality](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html) we can group the entire dataset in a wide variety of ways and apply builtin or user-defined functions.\n",
    "\n",
    "In the example below, we group the 5 year dataset by month, day and hour and take the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = owp.index\n",
    "typical_owp_year = owp.groupby([idx.month,idx.day,idx.hour]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can then plot the resulting representitive year of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format ='retina' #notebook commands are not needed in separate scripts\n",
    "%matplotlib widget #notebook commands are not needed in separate scripts\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "from pandas import to_datetime\n",
    "\n",
    "years = mdates.YearLocator()  # every year\n",
    "days = mdates.DayLocator()\n",
    "months = mdates.MonthLocator()  # every month\n",
    "years_fmt = mdates.DateFormatter('%m')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(owp.loc['1996'].index, typical_owp_year/1000, \n",
    "        label='Omni-Directional Wave Power')\n",
    "\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(years_fmt)\n",
    "ax.xaxis.set_minor_locator(days)\n",
    "\n",
    "ax.format_xdata = mdates.DateFormatter('%m')\n",
    "plt.ylabel('Omni-Directional Wave Power (kW/m)')\n",
    "plt.xlabel('Time')\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "plt.title('Typical Year Calculation')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 5.3: Working with the Directional Wave Spectrum and Polar Plots \n",
    "\n",
    "Directional wave spectrum data is more complicated to work with in that we have the extra dimentions of frequency and direction within the dataset. These dataset are returned from HSDS as [Pandas Multi-index Dataframes](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html) and can be analyzed following that syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from rex import WaveX\n",
    "\n",
    "waveFile = f'/nrel/US_wave/virtual_buoy/US_virtual_buoy_1995.h5'\n",
    "lat_lon = (44.624076,-124.280097)\n",
    "spc_name = 'directional_wave_spectrum'\n",
    "\n",
    "with WaveX(waveFile, hsds=True) as waves:\n",
    "    spc = waves.get_lat_lon_df(spc_name, lat_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This examples gives a method for creating a polar plot of a yearly mean of directional spectrum data. \n",
    "\n",
    "One processing step below, fills the data gap at 0<sup>o</sup> and 2pi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import unique, array, radians, hstack, pi, newaxis, mean, meshgrid\n",
    "\n",
    "# pull degree values from Datasets and convert to radians\n",
    "directions = hstack([unique(radians(spc.index.get_level_values(level=2)))])\n",
    "\n",
    "# add angle 0 and 2pi\n",
    "azimuths = hstack([array(0),directions,2*pi])\n",
    "zeniths = unique(spc.index.get_level_values(level=1))\n",
    "\n",
    "# create the 2D meshgrid for plots and correctly orient the angles\n",
    "r, theta = meshgrid(zeniths, azimuths)\n",
    "theta = 90-theta\n",
    "\n",
    "# Calculate the mean across time and replace 0 values (for log scale) \n",
    "yearly_mean = spc.mean(level=(1,2)).values.reshape(zeniths.shape[0],azimuths.shape[0]-2)\n",
    "yearly_mean[yearly_mean<=0] = 1e-9\n",
    "\n",
    "# populate the 0 and 2pi directions of the data\n",
    "edges = mean([yearly_mean[:,0],yearly_mean[:,-1]],axis=0)\n",
    "yearly_mean = hstack([edges[:,newaxis],hstack([yearly_mean,edges[:,newaxis]])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "With the corrections made we can create the plot of directional wave spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format ='retina' #notebook commands are not needed in separate scripts\n",
    "%matplotlib widget #notebook commands are not needed in separate scripts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import LogLocator\n",
    "import matplotlib as mpl\n",
    "\n",
    "font = {'family' : 'DejaVu',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 10}\n",
    "\n",
    "mpl.rc('font', **font)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw=dict(projection='polar'))\n",
    "cs = ax.contourf(theta, r, yearly_mean.T, \n",
    "                 locator=LogLocator(numticks=50)\n",
    "                )\n",
    "ax.set_theta_zero_location(\"N\")\n",
    "ax.set_xticklabels(['N', 'NW', 'W', 'SW', 'S', 'SE', 'E', 'NE'])\n",
    "\n",
    "label_position = ax.get_rlabel_position()\n",
    "ax.text(\n",
    "        radians(label_position+10),ax.get_rmax()/2.,'Frequency (Hz)',\n",
    "        rotation=label_position-90,ha='center',va='center'\n",
    "        )\n",
    "ax.set_title(\"Directional Wave Spectrum\", va='bottom')\n",
    "\n",
    "cbar = plt.colorbar(cs)\n",
    "cbar.ax.set_ylabel(r'Frequency Amplitude (m^2/Hz/deg)', rotation=270,\n",
    "                   fontsize=font['size'],fontweight=font['weight']\n",
    "                  )\n",
    "plt.tight_layout()\n",
    "plt.grid(linestyle=':',color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 5.4: Creating and Plotting a Joint Probability Distribution\n",
    "\n",
    "We can quickly calculate a JPD based on the 1-hr bulk parameters from the Virtual Buoy datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rex import WaveX\n",
    "\n",
    "waveFile = f'/nrel/US_wave/virtual_buoy/US_virtual_buoy_1995.h5'\n",
    "lat_lon = (44.624076,-124.280097)\n",
    "Hm0_name = 'significant_wave_height'\n",
    "Te_name = 'peak_period'\n",
    "Dir_name = 'mean_wave_direction'\n",
    "\n",
    "with WaveX(waveFile, hsds=True) as waves:\n",
    "    Hm0 = waves.get_lat_lon_df(Hm0_name, lat_lon)\n",
    "    Te = waves.get_lat_lon_df(Te_name, lat_lon)\n",
    "    Dir = waves.get_lat_lon_df(Dir_name, lat_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "For the JPD we can make use of numpy's builtin functions to handle much of the heavy lifting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import histogramdd, array, arange\n",
    "from pandas import DataFrame\n",
    "\n",
    "# Generate bins for Hm0 and Te, input format (start, stop, step_size)\n",
    "Hm0_bins = arange(0, Hm0.values.max() + 0.5, 0.5)    \n",
    "Te_bins = arange(0, Te.values.max() + 1, 1)\n",
    "\n",
    "# Combine data for better handling\n",
    "jpd_data = array([Hm0.values.flatten(),Te.values.flatten()]).T\n",
    "\n",
    "# Calculate the bin centers of the data\n",
    "Hm0_center = array([\n",
    "                    mean([Hm0_bins[i+1],Hm0_bins[i]]) \n",
    "                    for i in range(Hm0_bins.shape[0]-1)\n",
    "                ])\n",
    "Te_center = array([\n",
    "                    mean([Te_bins[i+1],Te_bins[i]]) \n",
    "                    for i in range(Te_bins.shape[0]-1)\n",
    "                ])\n",
    "\n",
    "# Calculate the JPD for Hm0 and Te and pack into a DataFrame\n",
    "probability, edges = histogramdd(jpd_data,bins=[Hm0_bins,Te_bins],density=True)\n",
    "jpd = DataFrame(probability, index=Hm0_center, columns=Te_center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can then plot the resulting JPD using matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format ='retina' #notebook commands are not needed in separate scripts\n",
    "%matplotlib widget #notebook commands are not needed in separate scripts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import arange\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "\n",
    "im = ax.imshow(jpd, origin='lower', aspect='auto')\n",
    "\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.set_label('Probability Density (1/(sec*m)', rotation=270, labelpad=15)\n",
    "\n",
    "ax.set_xlabel('Te (seconds)')\n",
    "ax.set_ylabel('Hm0 (meters)')\n",
    "\n",
    "ax.set_xticks(arange(len(jpd.columns)))\n",
    "ax.set_yticks(arange(len(jpd.index)))\n",
    "ax.set_xticklabels(jpd.columns)\n",
    "ax.set_yticklabels(jpd.index)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Joint Probability Distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example 5.5: Creating and Plotting a Directionaly Dependent JPD\n",
    "\n",
    "As an extension, we can catagorize our JPD calculation by the `'mean_wave_direction'` which can also be found in the *Virtual Buoy* Datasets. This is shown in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import histogramdd, array, arange, mean\n",
    "\n",
    "# Generate bins for Hm0, Te and Direction\n",
    "Hm0_bins = arange(0, Hm0.values.max() + 0.5, 0.5)    \n",
    "Te_bins = arange(0, Te.values.max() + 1, 1)\n",
    "Dir_bins = arange(0, Dir.values.max() + 10, 10)\n",
    "\n",
    "# Combine data for better handling\n",
    "jpd_3d = array([\n",
    "                    Hm0.values.flatten(),\n",
    "                    Te.values.flatten(),\n",
    "                    Dir.values.flatten()\n",
    "                ]).T\n",
    "\n",
    "# Calculate the bin centers of the data\n",
    "Hm0_center = array([\n",
    "                    mean([Hm0_bins[i+1],Hm0_bins[i]]) \n",
    "                    for i in range(Hm0_bins.shape[0]-1)\n",
    "                ])\n",
    "Te_center = array([\n",
    "                    mean([Te_bins[i+1],Te_bins[i]]) \n",
    "                    for i in range(Te_bins.shape[0]-1)\n",
    "                ])\n",
    "Dir_center = array([\n",
    "                    mean([Dir_bins[i+1],Dir_bins[i]]) \n",
    "                    for i in range(Dir_bins.shape[0]-1)\n",
    "                ])\n",
    "\n",
    "\n",
    "# Calculate the JPD for Hm0, Te, and Dir \n",
    "probability, edges = histogramdd(jpd_3d,bins=[Hm0_bins,Te_bins,Dir_bins],density=True)\n",
    "\n",
    "# The JPD Now includes the Directional arguement\n",
    "print(f'Shape of the 3 component JPD: {probability.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "To check the consistency of the probability density calculation we can perform a Volumn integral check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import diff, einsum, sum\n",
    "d = diff\n",
    "x, y, z = edges\n",
    "\n",
    "integral = sum(probability*einsum('i,j,k->ijk',d(x),d(y),d(z)))\n",
    "\n",
    "print(f'Integral of the Hm0, Te, Direction JPD: {integral}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can add interactivity to the JPD to allow use to view data over the direction bins we have added to the JPB. In this case we can get a sense of the yearly JPD of various sea-states coming from a specific direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format ='retina' #notebook commands are not needed in separate scripts\n",
    "%matplotlib widget #notebook commands are not needed in separate scripts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import arange\n",
    "from matplotlib.widgets import Slider\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.subplots_adjust(right=0.8, bottom=0.25)\n",
    "\n",
    "d = 0\n",
    "plot_jpd = probability[:,:,d]\n",
    "\n",
    "im = ax.imshow(plot_jpd, origin='lower', aspect='auto')\n",
    "\n",
    "axcolor = 'lightgoldenrodyellow'\n",
    "axDir = plt.axes([0.3, 0.075, 0.45, 0.03], facecolor=axcolor)\n",
    "\n",
    "newD = Slider(axDir, 'Income Wave\\n Direction', 5, 355, valinit=d, valstep=10)\n",
    "\n",
    "def update(val):\n",
    "    d = int(newD.val/10)\n",
    "    im.set_data(probability[:,:,d])\n",
    "    fig.canvas.draw()\n",
    "\n",
    "newD.on_changed(update)\n",
    "\n",
    "cax = fig.add_axes([0.82, 0.3, 0.03, 0.5])\n",
    "cbar = fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "\n",
    "cbar.set_label('Probability Density (1/(sec*m*deg)', rotation=270, labelpad=15)\n",
    "\n",
    "ax.set_xlabel('Te (seconds)')\n",
    "ax.set_ylabel('Hm0 (meters)')\n",
    "\n",
    "ax.set_xticks(arange(len(Te_center)))\n",
    "ax.set_yticks(arange(len(Hm0_center)))\n",
    "ax.set_xticklabels(Te_center,rotation=45)\n",
    "ax.set_yticklabels(Hm0_center)\n",
    "\n",
    "fig.suptitle('Joint Probability Density\\n of Hm0 and Te per Direction')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "In this tutorial we have covered several important topics when looking to work with the **WPTO Wave Hindcast Datasets**. In summary we have covered:\n",
    "- Installation of the REsource eXtraction Toolkit (rex)\n",
    "- Using the rex CLI to pull raw data from the AWS HSDS data servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "rise": {
   "font size": "5",
   "scroll": true,
   "theme": "sky",
   "transition": "zoom"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
